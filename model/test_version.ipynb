{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_version.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c6f061c7754a4a488615e78875618fc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fe49e2b3bddc475a94d49ba86ce0b77f",
              "IPY_MODEL_a7e1dd3ffa484ca09efc734bf8e4a66c",
              "IPY_MODEL_72a31f3cb8b84d17821772655281c81b"
            ],
            "layout": "IPY_MODEL_a2b6aed5ecde42d487098b32c1e74b03"
          }
        },
        "fe49e2b3bddc475a94d49ba86ce0b77f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2698ba983d9445088cfafa8b6dbabbef",
            "placeholder": "​",
            "style": "IPY_MODEL_8d84d561728b4f898c058ea6e7785e22",
            "value": "100%"
          }
        },
        "a7e1dd3ffa484ca09efc734bf8e4a66c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcc47157f60a4e26bb6eca58cb0da1f5",
            "max": 244408911,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_648d231625fd4cf7859aeef74befa4f5",
            "value": 244408911
          }
        },
        "72a31f3cb8b84d17821772655281c81b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e28c305131ea4c609fc5c7e5439cdc1c",
            "placeholder": "​",
            "style": "IPY_MODEL_e88607d123b64dd6ba9cff5d6ef8b8b0",
            "value": " 233M/233M [00:18&lt;00:00, 18.0MB/s]"
          }
        },
        "a2b6aed5ecde42d487098b32c1e74b03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2698ba983d9445088cfafa8b6dbabbef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d84d561728b4f898c058ea6e7785e22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dcc47157f60a4e26bb6eca58cb0da1f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "648d231625fd4cf7859aeef74befa4f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e28c305131ea4c609fc5c7e5439cdc1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e88607d123b64dd6ba9cff5d6ef8b8b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unnA5Dodaq14"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import itertools\n",
        "import math\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "from os.path import isfile\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ANNClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ANNClassifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(256 * 6 * 6, 200)\n",
        "        self.fc2 = nn.Linear(200, 74)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 256 * 6 * 6) #flatten feature data\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "3p7vnloxbChf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading model\n",
        "model = ANNClassifier()\n",
        "model.cuda()\n",
        "state = torch.load(os.getcwd()+\"/final_model\")\n",
        "model.load_state_dict(state)\n",
        "\n",
        "AlexNet = models.alexnet(pretrained=True)\n",
        "\n",
        "data_transform = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()])\n",
        "\n",
        "\n",
        "labels_map = ['!', '(', ')', '+', ',', '-', \n",
        "           '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', \n",
        "           '=', 'a', 'c', '\\delta', 'g', 'h', 'm', 'n', 'r', 's', 't', 'x', \n",
        "           '\\alpha', 'b', '\\beta', '\\cos', 'd', '\\div', 'e', 'f', \n",
        "           '\\forall', '\\gamma', '\\geq', '>', 'i', '\\in', '\\infty', '\\int',\n",
        "           'j', 'k', 'l', '\\lambda', '\\leq', '\\lim', '\\log', '<', '\\mu', '\\neq',\n",
        "           'o', 'p', '\\phi', '\\pi', '\\pm', 'q', '\\sigma', '\\sin', '\\sqrt{',\n",
        "           '\\sum', '\\tan', '\\theta', '\\times', 'u', 'v', 'w', 'y', 'z', '\\{', '\\}']"
      ],
      "metadata": {
        "id": "l5iYYydAbEmo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "c6f061c7754a4a488615e78875618fc6",
            "fe49e2b3bddc475a94d49ba86ce0b77f",
            "a7e1dd3ffa484ca09efc734bf8e4a66c",
            "72a31f3cb8b84d17821772655281c81b",
            "a2b6aed5ecde42d487098b32c1e74b03",
            "2698ba983d9445088cfafa8b6dbabbef",
            "8d84d561728b4f898c058ea6e7785e22",
            "dcc47157f60a4e26bb6eca58cb0da1f5",
            "648d231625fd4cf7859aeef74befa4f5",
            "e28c305131ea4c609fc5c7e5439cdc1c",
            "e88607d123b64dd6ba9cff5d6ef8b8b0"
          ]
        },
        "outputId": "03ac76f8-2d80-4f47-d8ee-edaed360bb0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/233M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c6f061c7754a4a488615e78875618fc6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image(path):\n",
        "    \"\"\" load the image as black and white\n",
        "\n",
        "    Args:\n",
        "        path: a string with path to image to be load\n",
        "    Returns:\n",
        "        img: a ndarray for orginal image in grayscale, purely black(0) and white(255)\n",
        "        thresh: a ndarray for orginal image in grayscale with invert colour, purely black(0) and white(255)\n",
        "    \"\"\"\n",
        "    img = cv2.imread(path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # convert image to grayscale\n",
        "    ret, thresh = cv2.threshold(img, 200, 255, cv2.THRESH_BINARY_INV)  # convert image to solely black (0) and white (255) in invert colour\n",
        "    ret2, img = cv2.threshold(img, 200, 255, cv2.THRESH_BINARY)\n",
        "    return img,thresh\n",
        "\n",
        "\n",
        "def contour_info(thresh,contours):\n",
        "    \"\"\" find the position information for each contour in the image\n",
        "\n",
        "    Args:\n",
        "        thresh: a ndarray in grayscale with invert colour\n",
        "        contours: a list contain points for each contour\n",
        "    Returns:\n",
        "        start_x: a list with the starting x position for each contour, stored form left to right\n",
        "        info: a list position info for each contour, stored form left to right. Format: contour_idx, width, starting_y, height\n",
        "    \"\"\"\n",
        "    by_x = {} # position info for segments with starting x position as key\n",
        "\n",
        "    for i in range(len(contours)):\n",
        "      x, y, w, h = cv2.boundingRect(contours[i]) # getting position info for each contour\n",
        "      if x in by_x.keys():\n",
        "        if(isinstance(by_x[x][0],list)):\n",
        "          by_x[x] = sum(by_x[x], [])\n",
        "        by_x[x] = [by_x[x],[i, w, y, h]]\n",
        "      else:\n",
        "        by_x[x] = [i, w, y, h]\n",
        "\n",
        "\n",
        "    by_x_sort = sorted(by_x.items()) # sort the contours from left to right\n",
        "\n",
        "    start_x,info = [],[]\n",
        "    for pos in by_x_sort:\n",
        "      if(isinstance(pos[1][0],list)):\n",
        "          for inf in pos[1]:\n",
        "            start_x.append(pos[0])\n",
        "            info.append(inf)\n",
        "      else:\n",
        "          start_x.append(pos[0])\n",
        "          info.append(pos[1])\n",
        " \n",
        "    return start_x, info\n",
        "\n",
        "\n",
        "def find_seg(start_x, info):\n",
        "    \"\"\" combine contours for each math symbol\n",
        "\n",
        "    Args:\n",
        "        start_x: a list with the starting x position for contours\n",
        "        info: a list position info for each contour\n",
        "    Returns:\n",
        "        crop: a list for position info for individual symbol. Format: starting_x, width, starting_y, height, contour_idx\n",
        "    \"\"\"\n",
        "    crop = [] \n",
        "    combined = [] # list to store index of combined contour\n",
        "\n",
        "    crop_idx = 0 # current index of segment\n",
        "\n",
        "    for i in range(len(info)):\n",
        "        # skip this contour if is combined with previous contours\n",
        "        if (info[i][0] in combined): \n",
        "            continue\n",
        "        crop.append([start_x[i], info[i][1], info[i][2], info[i][3],[info[i][0]]]) # format: x,w,y,h,i\n",
        "\n",
        "        # check all contour on the left to see if need to combine\n",
        "        for j in range(i + 1, len(start_x)):\n",
        "\n",
        "            # check if start at almost same x position and if width is similar\n",
        "            if ((start_x[j] - start_x[i]) < info[i][1] / 2.5):\n",
        "                if (abs(info[i][1] - info[j][1]) < (max(info[i][1], info[j][1]) / 3)):\n",
        "                \n",
        "                    crop[crop_idx][1] = max(crop[crop_idx][1] + crop[crop_idx][0], info[j][1] + start_x[j]) - crop[crop_idx][0]\n",
        "                    if (crop[crop_idx][2] < info[j][2]):\n",
        "                        crop[crop_idx][3] = info[j][2] - crop[crop_idx][2] + info[j][3]\n",
        "                    else:\n",
        "                        crop[crop_idx][3] += crop[crop_idx][2] - info[j][2]\n",
        "                        crop[crop_idx][2] = info[j][2]\n",
        "\n",
        "                    crop[crop_idx][4].append(info[j][0])\n",
        "                    combined.append(info[j][0])\n",
        "            # stop checking if this contour is already far enough\n",
        "            else:\n",
        "              break\n",
        "        crop_idx += 1\n",
        "    return crop\n",
        "\n",
        "\n",
        "def crop_seg(crop, img, thresh, contours):\n",
        "    \"\"\" crop each symbol from orginal image\n",
        "\n",
        "    Args:\n",
        "        crop: a list for position info for each symbol\n",
        "        img: a ndarray for orginal image in grayscale\n",
        "        thresh: a ndarray for orginal image in grayscale, with invert colour\n",
        "        contours: a list contain points for each contour\n",
        "    Returns:\n",
        "        segments: a list to store each symbol as grayscale\n",
        "    \"\"\"\n",
        "    segments = [] \n",
        "\n",
        "    for seg in crop:\n",
        "        # clear everything except current segemnt\n",
        "        white_img = np.full((img.shape[0], img.shape[1]), 0, dtype='uint8')\n",
        "        for idx in seg[4]:\n",
        "          inv_color = thresh.copy()\n",
        "          cv2.drawContours(inv_color, contours, idx, 0, -1)\n",
        "          white_img += cv2.bitwise_not(inv_color+img)\n",
        "    \n",
        "        white_img = cv2.bitwise_not(white_img)\n",
        "    \n",
        "        symbol = white_img[seg[2]:seg[2] + seg[3], seg[0]:seg[0] + seg[1]]\n",
        "    \n",
        "        # pad current segment if is too thin \n",
        "        if (seg[3] < seg[1] / 2.5):\n",
        "            white = np.full((int((seg[1] - seg[3]) / 2), seg[1]), 255, dtype='uint8')\n",
        "            symbol = np.vstack([white, symbol, white])\n",
        "        elif (seg[1] < seg[3] / 2.5):\n",
        "            white = np.full((seg[3], int((seg[3] - seg[1]) / 2)), 255, dtype='uint8')\n",
        "            symbol = np.c_[white, symbol, white]\n",
        "    \n",
        "        segments.append(symbol)\n",
        "\n",
        "    return segments\n",
        "\n",
        "def get_result(crop, segments):\n",
        "    \"\"\" pass each segment to model and get the recoginzed equation\n",
        "\n",
        "    Args:\n",
        "        crop: a list for position info for each symbol\n",
        "        segments: a list to store each symbol as grayscale\n",
        "    Returns:\n",
        "        result: a string that represent the equation in LaTex\n",
        "    \"\"\"\n",
        "    result = \"\"\n",
        "    exp = False # if currently is exponent \n",
        "    exp_end  = False\n",
        "    sqrt = False # if currently in squart root\n",
        "    sqrt_end = 0\n",
        "    bottom = False # if currently in lower part\n",
        "    bottom_end = False\n",
        "\n",
        "    for i in range(len(segments)):\n",
        "      # enter exponent if current is above previous\n",
        "\n",
        "      current_seg = cv2.cvtColor(segments[i],cv2.COLOR_GRAY2RGB)\n",
        "      current_seg = Image.fromarray(current_seg)\n",
        "      current_seg = data_transform(current_seg)\n",
        "\n",
        "      current_seg = AlexNet.features(current_seg).cuda()\n",
        "\n",
        "      pred = labels_map[model(current_seg).max(1, keepdim=True)[1]]\n",
        "\n",
        "      if (i > 0 and not bottom_end\n",
        "          and (crop[i][2] + crop[i][3] < crop[i - 1][2] + crop[i - 1][3] * 1 / 3)):\n",
        "        result += '^{'\n",
        "        exp = True\n",
        "      \n",
        "      if (i > 0 and not exp_end\n",
        "          and (crop[i][2]  > crop[i - 1][2] + crop[i - 1][3] * 2 / 3)):\n",
        "        result += '_{'\n",
        "        bottom = True\n",
        "\n",
        "      result += pred\n",
        "\n",
        "      if(pred=='\\sqrt{'):\n",
        "        sqrt_end = crop[i][0] + crop[i][1]\n",
        "        sqrt = True\n",
        "        if( i>0 and crop[i - 1][0] + crop[i - 1][1]>crop[i][0]):\n",
        "          result = result[0:len(result)-7]+'\\sqrt['+result[len(result)-7]+']{'\n",
        "\n",
        "      exp_end = False\n",
        "      bottom_end = False\n",
        "      if(pred==',' and exp == True):\n",
        "        result = result[0:len(result)-3]+'\\prime'\n",
        "        exp = False\n",
        "        exp_end = True\n",
        "      \n",
        "      if (bottom and (i + 1 == len(segments) or crop[i][2]> crop[i + 1][2] + crop[i + 1][3] * 2 / 3)):\n",
        "        result += '}'\n",
        "        bottom = False\n",
        "        bottom_end = True\n",
        "      \n",
        "      if (exp and (i + 1 == len(segments) or crop[i][2] + crop[i][3] < crop[i + 1][2] + crop[i + 1][3] * 1 / 3)):\n",
        "        result += '}'\n",
        "        exp = False\n",
        "        exp_end = True\n",
        "\n",
        "      if(sqrt and (i+1 ==len(segments) or crop[i+1][0]>=sqrt_end )):\n",
        "        result+='}'\n",
        "      \n",
        "\n",
        "    return result\n",
        "\n",
        "def show_img(images):\n",
        "    \"\"\" display each image of equation/segment in grayscale\n",
        "\n",
        "    Args:\n",
        "        images: a list to store pixel of each image\n",
        "    \"\"\"\n",
        "    i = 0\n",
        "    row = math.ceil(len(images)/5)\n",
        "    for im in images:\n",
        "      plt.subplot(row,5, i + 1)\n",
        "      plt.imshow(im, 'gray', vmin=0, vmax=255)\n",
        "      plt.title(i)\n",
        "      plt.xticks([])\n",
        "      plt.yticks([])\n",
        "      i += 1"
      ],
      "metadata": {
        "id": "xiQRjywFbQR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip v1_final_data_eqns_square -d datas # change v1_final_data_eqns_square to zip file name"
      ],
      "metadata": {
        "id": "d2k1O1FylBIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# google don't support cv2.imshow\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# filename should be in A column and labels in B column in excel\n",
        "eqns = pd.read_excel(os.getcwd()+\"/ground_truth_eqns.xlsx\") # change the path to the excel with file name & ground true label\n",
        "filename = eqns['File Name'].tolist() # change 'File Name' to name of column of your file name\n",
        "ground_true = eqns['LaTeX'].tolist() # change 'LaTeX' to name of column of your ground truw label\n",
        "\n",
        "wrong,total = 0,0\n",
        "for name,label in zip(filename,ground_true):\n",
        "      path = os.getcwd()+'/datas/'+name.replace(\" \", \"\")\n",
        "      label = str(label).replace(\" \", \"\").casefold()\n",
        "\n",
        "      if not isfile(path) or label== '':\n",
        "        continue\n",
        "\n",
        "      img,thresh = load_image(path)\n",
        "      contours, hierarchy=cv2.findContours(thresh,cv2.RETR_EXTERNAL ,cv2.CHAIN_APPROX_SIMPLE ) \n",
        "      start_x, info = contour_info(thresh,contours)\n",
        "      crop = find_seg(start_x, info)\n",
        "      segments = crop_seg(crop, img, thresh,contours)\n",
        "      result = get_result(crop,segments)\n",
        "\n",
        "      if(result!=label and label!= ''):\n",
        "      \n",
        "        print(\"\\nresult:\",result,\"\\nlabel: \",label)\n",
        "        print('diff # ',sum(x!=y for x,y in zip(result,label)))\n",
        "        wrong += 1\n",
        "        print(path)\n",
        "        cp = img.copy()\n",
        "        for seg in crop:\n",
        "          cv2.rectangle(cp, (seg[0], seg[2]), (seg[0] + seg[1], seg[2] + seg[3]), (0, 0, 255), 2)\n",
        "        cv2_imshow(img)\n",
        "        cv2_imshow(cp)\n",
        "        wrong+=1\n",
        "      total += 1\n",
        "      \n",
        "print('\\naccuracy: ', (total-wrong)/total)"
      ],
      "metadata": {
        "id": "sTcPSx56B70P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to test a single image and see each segment in order\n",
        "path = os.getcwd()+'/datas/image_name.png' # change image_name.png to name of image\n",
        "\n",
        "img,thresh = load_image(path)  \n",
        "contours, hierarchy=cv2.findContours(thresh,cv2.RETR_EXTERNAL ,cv2.CHAIN_APPROX_SIMPLE ) \n",
        "start_x, info = contour_info(thresh,contours)\n",
        "crop = find_seg(start_x, info)\n",
        "segments = crop_seg(crop, img, thresh,contours)\n",
        "result = get_result(crop,segments)\n",
        "\n",
        "cp = img.copy()\n",
        "for seg in crop:\n",
        "    cv2.rectangle(cp, (seg[0], seg[2]), (seg[0] + seg[1], seg[2] + seg[3]), (0, 0, 255), 2) # draw rectangle around each segment\n",
        "\n",
        "cv2_imshow(img) # display orginal image\n",
        "cv2_imshow(cp) # display image with square around each segment \n",
        "show_img(segments) # display each segment in order\n",
        "print(result) # display result"
      ],
      "metadata": {
        "id": "jKBycC7i8aK8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}